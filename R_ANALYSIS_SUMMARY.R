정리

1. 이론 + 각 분석의 장단점 + 사용이유
2. 수행과정 with tuning
3. 예제 & 연습문제

# [ 분석 기초 ]
# 1. 데이터 분석
# - 데이터 마이닝 : 데이터로부터 의미 있는 정보(현상)를 찾는 분석 기법
#   ex) 비오는날 빨간립스틱의 수요가 증가함을 발견

# 2. 미래 예측
# 머신러닝(정형데이터)
# 사용자가 데이터로부터 직접 패턴을 찾는게 아닌 기계(모델)가 데이터의 학습을 
# 통해 규칙을 찾아주는 분석 기법

# 2.1 지도학습 : 예측값(Y)이 존재 o
# X ~ Y 

#   1) 회귀기반(Y가 연속형) : 수요예측, 부동산가격예측 ...
#   2) 분류기반(Y가 범주형) : 이탈예측, 생존여부예측, ... 
#   - 트리기반 모델
#   - 거리기반 모델
#   - 확률/통계 모델
#   - 신경망 모델(딥러닝)

# 2.2 비지도학습 : 예측값(Y)이 존재 x
#   1) 군집분석 (거리기반 모델) => 평가 없음
#   2) 연관분석
#   3) 딥러닝(비정형데이터)
#   - 인공지능 > 머신러닝 > 딥러닝
#   - 신경망 구조의 머신러닝 기법을 딥러닝이라 표현
#   - 주로 비정형데이터의 분석 시 사용
#   - 블랙박스 모델 : 결과만 확인가능, 패턴(원인)은 파악하기 어려움

# ------------------------------------------------------------------------------

# [ 지도학습 - 분석 1. 분류 분석 - 범주형 ]
# - 지도학습의 일부 (Y가 존재)
# - Y가 범주형인 경우
# - 대표적 모델로 트리기반 모델, 거리기반 모델, 확률통계기반 모델 존재

# [ Data Analysis Process - 분류분석, 비통계적]
# 0) Setting Purpose of Analysis
# 1) data loading (데이터 수집 - Y의 분류에 영향을 미칠 것 같은 X들을 수집)
# 2) preprocessing (데이터 전처리 - 이상치/결측치 제거 및 수정)
# 3) model selection based on data (모델 선택)
# 4) data split into train/test (데이터 분리)
# 5) model fitting by train data set (모델 학습)
# 6) model scoring by test data set (모델 평가)
# - 비통계적이기 때문에 모델평가가 어려움 => 몇개 중 몇개를 맞췄는지로 판단
# - 모델의 학습과 평가의 데이터셋은 분리시킴 => 같은 데이터 사용 시 확률 높아지는 문제발생
# 7) model tuning (모델 튜닝)
# 8) review & apply

# 1.1 트리기반 모델
# 1.1.1 Decision Tree (트리기반 모델)
# - 분류 분석을 수행하는 트리기반 모델의 가장 시초 모델
# - 패턴 학습이 단순하여 패턴을 시각화 할 수 있음
# - 패턴이 Tree 구조를 띔
# - 비통계적 모델이므로 모델 해석이 매우 용이
# - 단일 의사결정이므로 예측력이 불안하거나 과대적합 가능성 있음

# [ 트리 기반 모델의 변수 선택 기능 ]
# - 트리 모델은 각 변수의 중요도를 자식 노드의 불순도를 통해 계산
# - 중요도가 높은 변수를 상위 split 조건으로 사용
# - 변수간 중요도 차이가 큰 경우 특정 변수만 재사용 가능성 있음
# - 트리 모델의 변수 중요도는 분석 시 중요 변수 파악에 용이하게 사용

# [ 불순도 ]
# - 특정 조건으로 인해 분리된 자식노드의 클래스의 혼합 정도
# - 주로 지니계수로 측정
# - 2개의 class를 갖는경우 f(p) = p(1-p)로 계산

# 예제) 
# - AAAAAA : p(A가 속할 확률) = 1, f(p) = 1 * (1-1) = 0
# - AAAABB : p = 4/6, f(p) = 4/6 * 2/6 = 0.22
# - AAABBB : p = 1/2, f(p) = 1/2 * 1/2 = 0.25

# decision tree에서 변수 중요도 확인
iris_dt2$variable.importance

# Petal.Width Petal.Length Sepal.Length  Sepal.Width 
# 62.64908     61.22238     39.67210     26.34410 

# 1.2 조건부 추론 나무
# - 기존 decision tree를 보안
# - 분류 기준에 따른 적합성을 통계적으로 해석하는 장치 추가
#   (변수의 유의성 검정)

# 1.3 Ramdom Forest
# - Decision Tree의 과대적합 현상을 해결하기 위해 여러개의 서로 다른
#   모양의 tree를 구성, 종합하여 최종 결론을 내는 방식
# - Random Forest Classifier와 Random Forest Regressor 존재
# - 분류모델인 경우는 다수결로, 회귀모델인 경우는 평균으로 최종결론
# ---------------------------------------------------------------------------- #

# [ 지도학습 - 분석 2. 분류 분석 - 연속형 ]
# 1) 전통 회귀 분석
# - 여러가지 통계적 가정 필요
# - 가정이 성립되지 않으면 예측력이 떨어짐
# - 인과관계 파악이 용이
# 
# 2) 분류모델이 제공하는 회귀 모델
#    (ex. ramdomForest-classification)
# - 비 통계적 모델
# - 특별한 튜닝 없이도 우수한 예측력 갖음
# - 인과관계 파악은 불가(예측에 집중)

# 2.1 트리기반 모델
# - DT -> RF -> GB -> XGB
# - outlier 민감 X
# - 범주, 연속형 설명변수 모두 포함 가능
# - 학습시간에 비해 예측시간이 빠름
# - 연속형 데이터에 대한 scaling 필요 X
# 
# 2.2 거리기반 모델
# - outlier 매우 민감 => 제거/수정
# - 범주형 설명 변수가 많이 포함될수록 예측력 떨어짐
# - 고차원 데이터에 비적합
# - 예측 시간이 오래걸 림(학습과정 생략)
# - 연속형 데이터에 대한 scaling 필요 (표준화)
# - 모델에 학습되는 설명변수의 조합이 매우 중요한 모델

# 2.2.1 knn 
# - 예측하고자 하는 관측치로부터 기존관측치와의 거리 계산
# - 계산된 거리중 k개의 가장 가까운 이웃 관측치 확인
# - k개의 이웃이 갖는 정답(Y)의 평균 혹은 다수결로 최종 결론 내림
# - 설명변수의 스케일링 필요
# - Y class의 개수의 배수가 되는 k수는 적절치 않음
# - 모델에 학습되는 설명변수의 조합이 매우 중요한 모델
# ---------------------------------------------------------------------------- #

# [ 비지도학습 - 분석 1. 군집 분석 ]
# - 정답이 없는 비지도학습
# - 주어진 데이터들을 유사성에 근거해 비슷한 데이터끼리 묶는 분석기법
# - 초기 데이터에 대한 연구를 위해 사용되거나
#   클러스터링된 군집에 대한 정보를 추가로 활용하기 위해 주로 사용
# - 데이터 축소 테크닉
# - 거리기반 모델

# 1.1 계층적 군집분석
# - 거리가 짧은 데이터끼리 순차적으로 군집을 형성하는 과정
# - 한번 속한 군집은 변경되지 X
# - 군집과 데이터와의 거리를 정의하는 방식에 따라
#   최단거리법, 최장거리법, 평균거리법, 중앙거리법으로 나뉨

# 1.1.1 군집 형성 과정(군집과 데이터포인트와의 거리 측정 방식에 따라)
# 1) 최단거리법(single, min)
# 2) 최장거리법(complete, max)
# 3) 평균거리법(average)
# 4) 중앙거리법(median)

# 1.1.2 군집분석에서의 분산
# 1) 총분산(total_ss)
# 2) 그룹내 분산(within_ss)
# - 각 클러스터의 중심으로부터 각 클러스터 관측치가 떨어진 정도
# - 그룹내 분산은 작을수록 좋은 클러스터링 결과
# - 그룹의 개수가 커질수록 그룹내 분산도 작아짐

# 3) 그룹간 분산(between_ss)
# - 각 클러스터의 중심이 전체중심으로부터 흩어진 정도
# - 그룹간 분산은 클수록 각 클러스터의 이질성을 대변하므로 좋은 결과
# - 그룹의 개수가 커질수록 그룹내 분산도 커짐*

# total_ss = between_ss + within_ss

# 1.2 비계층적 군집분석
# - 거리가 짧은 데이터포인트끼리 묶는 방식은 동일
# - 계층적 군집분석과는 다르게 한번 클러스터에 소속된 관측치도
#   거리 측정 대상에 포함시켜 만약 다른 클러스터와의 거리가 더 짧다면
#   다른 클러스터로 이동되는 방식
# - 평가 metric존재 (그룹내/그룹간 분산에 의한 score)
# - 사용자가 직접 군집의 수를 정하면 해당 군집에 맞게 분류

# 1.2.1 비계층적 군집분석 수행 방식
# 1) 사용자가 지정한 k의 수만큼 랜덤하게 초기 중심(seed)값 추출
# 2) 위 seed로부터 각 관측치와의 거리 계산
# 3) 거리가 가장 가까운 관측치들을 각 클러스터에 할당
# 4) 변경된 클러스터의 중심을 재계산
# 5) 재계산된 클러스터의 중심으로 전체 데이터의 거리 모두 계산
# 6) 각 클러스터의 중심으로부터 가까운 데이터포인트 소속/이동
# 7) 위 과정을 더이상의 중심이 이동되지 않을때가지 계속 반복
# 8) 그룹 고정

# [ 변수선택법 (전진, 후진, stepwise) ]
# 1) 전진선택법(forward selection)
Y = X1
Y = X1 + X2 
Y = X1 + X2 + X3 

# 2) 후진선택법(backward selection)
Y = X1 + X2 + X3 + X4 + X5
Y = X1 + X2 + X3 + X4
Y = X1 + X2 + X3 

# 3) 단계적선택법(stepwise selection)
Y = X1 + X2 + X3 + X4 + X5
Y = X1 + X2 + X3 + X4
Y = X1 + X2 + X3             # 제거된 변수중 추가할 변수 있는지
Y = X1 + X2 + X3 + X5
# ------------------------------------------------------------------------------

# [ 이상치 검정 ]
# 1) Y가 연속형인 경우
# - 회귀모델 적용 후 이상치 검정 수행
# - 통계적 모델을 통한 유의성 검정 가능 (p-value)
# - car::outlierTest로 확인 가능

# 2) Y가 범주형인 경우
# - randomForest 모델 적용 후 이상치 검정 수행
# - 각 데이터포인트의 거리(유사성) 기반으로 이상치 확인
# - 유의성 검정 불가 (p-value 확인 불가)
# - outlier로 확인 가능
# ------------------------------------------------------------------------------